{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# AI101 – Assignment 2a: Chicago Crime Dataset Analysis\n",
    "\n",
    "**Dataset:** Chicago Crime Dataset (from Kaggle)  \n",
    "**Source:** [https://www.kaggle.com/datasets/chicago/chicago-crime](https://www.kaggle.com/datasets/chicago/chicago-crime)  \n",
    "\n",
    "This dataset contains over 7 million reported crime incidents in Chicago from 2001 to the present. Each record includes the crime type, location, whether an arrest was made, date and time, and other details. This notebook replicates the exploratory data analysis from Assignment 2, adapted for this richer, more complex dataset."
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-imports",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Importing Libraries\n",
    "\n",
    "We begin by importing all the libraries needed for data loading, manipulation, and visualization.\n",
    "\n",
    "- **`pandas`**: For loading the CSV and manipulating the DataFrame (filtering rows, grouping, aggregating).\n",
    "- **`numpy`**: For numerical operations and handling missing values represented as `NaN`.\n",
    "- **`matplotlib.pyplot`**: For creating foundational plots and customizing chart appearance.\n",
    "- **`seaborn`**: For higher-level statistical plots (heatmaps, count plots) that integrate naturally with pandas DataFrames.\n",
    "- **`warnings.filterwarnings('ignore')`**: Suppresses non-critical warning messages that can clutter the output (e.g., deprecation warnings from library updates). This keeps our output clean without hiding real errors.\n",
    "- **`%matplotlib inline`**: Ensures all plots render directly in the notebook output cells rather than in a separate pop-up window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set a consistent visual style for all plots\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-load",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Loading the Chicago Crime Dataset\n",
    "\n",
    "We load the dataset from the uploaded CSV file. Because the full dataset contains millions of rows, we use `nrows` to limit the load to 500,000 records — enough for a thorough analysis without exhausting Colab's memory.\n",
    "\n",
    "- **`pd.read_csv('Crimes_-_2001_to_Present.csv', nrows=500000)`**: Reads the first 500,000 rows of the crime CSV into a DataFrame. The `nrows` parameter is critical for large datasets: attempting to load all 7+ million rows at once could crash the runtime.\n",
    "- **`parse_dates=['Date']`**: Tells pandas to automatically parse the `Date` column as a proper `datetime` object instead of a plain string. This allows us to extract components like year, month, and hour directly from that column later.\n",
    "- **`df.head()`**: Previews the first 5 rows so we can see what columns exist and confirm the data loaded correctly.\n",
    "\n",
    "**What the output represents:** The first five crime records in our DataFrame, showing columns like `ID`, `Date`, `Primary Type` (type of crime), `Description`, `Location Description`, `Arrest` (whether an arrest was made), `Domestic`, `District`, `Ward`, `Latitude`, and `Longitude`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Crimes_-_2001_to_Present.csv',\n",
    "                 nrows=500000,\n",
    "                 parse_dates=['Date'])\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-structure",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Exploring the Shape and Structure\n",
    "\n",
    "Before cleaning or analyzing anything, we need to understand what columns we have and what types of data they contain.\n",
    "\n",
    "- **`df.shape`**: Returns `(rows, columns)`. With 500,000 rows loaded, this confirms how many features (columns) are available.\n",
    "- **`df.columns.tolist()`**: Prints the full list of column names. The Chicago Crime dataset has columns such as:\n",
    "  - `ID` – Unique crime identifier\n",
    "  - `Date` – Date and time of the incident\n",
    "  - `Primary Type` – Category of crime (e.g., THEFT, ASSAULT, HOMICIDE)\n",
    "  - `Description` – More specific description within the primary type\n",
    "  - `Location Description` – Type of location (STREET, RESIDENCE, etc.)\n",
    "  - `Arrest` – Boolean: was an arrest made?\n",
    "  - `Domestic` – Boolean: was this a domestic incident?\n",
    "  - `District`, `Ward`, `Community Area` – Geographic identifiers\n",
    "  - `Latitude` / `Longitude` – GPS coordinates of the crime\n",
    "- **`df.dtypes`**: Shows the data type of each column — important for knowing how to handle each one.\n",
    "- **`df.info()`**: A concise summary including non-null counts, which immediately highlights columns with missing data.\n",
    "\n",
    "**What the output represents:** A complete structural profile of our dataset — how many columns there are, what they're named, and whether they are numeric, boolean, datetime, or text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-missing",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Checking for Missing Values\n",
    "\n",
    "Missing data is common in large administrative datasets like crime records — location coordinates might be absent, or community area codes may not have been recorded for older incidents.\n",
    "\n",
    "- **`df.isnull().sum()`**: For each column, counts the total number of `NaN` (null/missing) values.\n",
    "- **`/ len(df) * 100`**: Converts those counts to percentages so we can compare columns with very different numbers of missing values on an equal scale.\n",
    "- **`missing_df[missing_df['Missing Count'] > 0]`**: Filters to show only columns that actually have missing data, keeping the output concise.\n",
    "- **`sort_values('Missing %', ascending=False)`**: Sorts from highest to lowest missingness, so the most problematic columns appear at the top.\n",
    "\n",
    "**What the output represents:** A ranked table of columns with missing data and what percentage is missing. In the Chicago Crime dataset, `Latitude` and `Longitude` commonly have a small percentage of missing values (crimes reported without a precise location), and `Location` (a combined lat/lon string) mirrors those gaps. This informs our decision: we can still use the dataset for most analyses, but should drop rows with missing coordinates before doing any geographic mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-missing",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing_pct = df.isnull().sum() / len(df) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct.round(2)\n",
    "}).sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_df[missing_df['Missing Count'] > 0].to_string())"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-clean",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Cleaning the Data\n",
    "\n",
    "With an understanding of where the data is messy, we apply targeted cleaning steps.\n",
    "\n",
    "- **`df.drop_duplicates(subset='ID', inplace=True)`**: Removes duplicate crime records. We use `subset='ID'` to check only the unique crime ID column — if two rows share the same `ID`, only the first is kept. This is safer than comparing all columns, since some crimes may have the same details but legitimately different IDs.\n",
    "- **`df['Year'] = df['Date'].dt.year`**: Extracts the **year** from the parsed `Date` datetime column. The `.dt` accessor lets us pull out components like `.year`, `.month`, `.hour`, `.dayofweek`. This creates a new column `Year` that we'll use for time-series analysis.\n",
    "- **`df['Month'] = df['Date'].dt.month`**: Extracts the numeric **month** (1 = January, 12 = December).\n",
    "- **`df['Hour'] = df['Date'].dt.hour`**: Extracts the **hour** (0–23 on a 24-hour clock). This lets us analyze what time of day crimes occur most frequently.\n",
    "- **`df['DayOfWeek'] = df['Date'].dt.day_name()`**: Extracts the full day name (e.g., 'Monday', 'Tuesday') for day-of-week analysis.\n",
    "- **`df_geo = df.dropna(subset=['Latitude', 'Longitude'])`**: Creates a separate geo-filtered DataFrame for geographic analysis. We don't drop these rows from the main `df` because missing coordinates shouldn't exclude records from non-geographic analyses.\n",
    "\n",
    "**What the output represents:** Confirmation of the cleaned dataset size and the new time-based columns we extracted, which are essential for trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate crime records\n",
    "df.drop_duplicates(subset='ID', inplace=True)\n",
    "\n",
    "# Extract time-based features from the Date column\n",
    "df['Year']      = df['Date'].dt.year\n",
    "df['Month']     = df['Date'].dt.month\n",
    "df['Hour']      = df['Date'].dt.hour\n",
    "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "\n",
    "# Separate DataFrame for geographic analysis (drops rows with missing coordinates)\n",
    "df_geo = df.dropna(subset=['Latitude', 'Longitude']).copy()\n",
    "\n",
    "print(f\"Cleaned dataset: {df.shape[0]:,} records\")\n",
    "print(f\"Records with location data: {df_geo.shape[0]:,}\")\n",
    "print(f\"New columns added: {['Year','Month','Hour','DayOfWeek']}\")\n",
    "df.head(3)"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-describe",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Descriptive Statistics\n",
    "\n",
    "We now summarize the numeric and boolean columns to understand the dataset's basic properties.\n",
    "\n",
    "- **`df.describe()`**: Computes summary stats for all numeric columns: `ID`, `Beat`, `District`, `Ward`, `Community Area`, `X Coordinate`, `Y Coordinate`, `Year`, `Latitude`, `Longitude`, and our extracted `Month`, `Hour`.\n",
    "  - **`count`**: Confirms how many non-null values each column has.\n",
    "  - **`mean`**: For `Year`, this shows the average year of crimes in our 500k sample — tells us the temporal center of the data.\n",
    "  - **`min` / `max`**: For `Year`, shows the range of years. For `Hour`, confirms 0–23. For `Latitude`/`Longitude`, defines the geographic bounding box of Chicago in our data.\n",
    "  - **`std`**: For `Hour`, a high standard deviation confirms crimes are spread across all times of day rather than clustered.\n",
    "- **`df[['Arrest','Domestic']].mean() * 100`**: `Arrest` and `Domestic` are boolean columns (`True`/`False`). Taking the mean of a boolean column gives the proportion of `True` values. Multiplying by 100 gives the **percentage**. This tells us: what percent of reported crimes resulted in an arrest, and what percent were domestic incidents.\n",
    "\n",
    "**What the output represents:** Statistical summaries confirming the data's time range, geographic scope, and key behavioral rates (arrest rate and domestic incident rate) — crucial context for interpreting all further visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-describe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numeric Summary Statistics:\")\n",
    "display(df.describe().T.round(2))\n",
    "\n",
    "print(\"\\nBoolean Column Rates:\")\n",
    "rates = df[['Arrest', 'Domestic']].mean() * 100\n",
    "for col, rate in rates.items():\n",
    "    print(f\"  {col} rate: {rate:.1f}%\")"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-crime-types",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Top Crime Types\n",
    "\n",
    "The most fundamental question we can ask about this dataset is: what kinds of crimes are most common?\n",
    "\n",
    "- **`df['Primary Type'].value_counts()`**: Counts the occurrences of each unique crime type in the `Primary Type` column. Values are returned in descending order — the most common crime type appears first. The Chicago crime taxonomy includes categories like THEFT, BATTERY, CRIMINAL DAMAGE, NARCOTICS, ASSAULT, etc.\n",
    "- **`.head(15)`**: We take only the top 15 crime types to keep the chart readable. There are 30+ distinct crime types in the dataset, but the top 15 account for the vast majority of incidents.\n",
    "- **`sns.barplot(...)`**: Creates a horizontal bar chart (using `orient='h'`) where each bar's length represents the count of that crime type.\n",
    "- **`plt.xscale('log')`**: Applies a **logarithmic scale** to the x-axis. This is necessary because crime counts vary enormously — THEFT may appear 100,000 times while HOMICIDE appears only a few hundred. A log scale compresses large differences so all bars remain visible and comparable. Without it, the rare crime types would appear as nearly invisible thin bars.\n",
    "\n",
    "**What the output represents:** A ranked visualization of Chicago's most common crime types. THEFT typically dominates, followed by BATTERY and CRIMINAL DAMAGE. This tells us where public safety resources are most in demand and which categories merit deeper investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-crime-types",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_counts = df['Primary Type'].value_counts().head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x=crime_counts.values, y=crime_counts.index, palette='rocket_r')\n",
    "plt.title('Top 15 Crime Types in Chicago', fontsize=15, fontweight='bold')\n",
    "plt.xlabel('Number of Incidents (log scale)')\n",
    "plt.ylabel('Crime Type')\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 15 Crime Type Counts:\")\n",
    "print(crime_counts.to_string())"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-arrest-rate",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Arrest Rate by Crime Type\n",
    "\n",
    "Beyond just counting crimes, we want to know which types of crimes are most likely to lead to an arrest — a key metric of law enforcement effectiveness.\n",
    "\n",
    "- **`df.groupby('Primary Type')['Arrest'].mean()`**: This is a **groupby + aggregation** operation — one of the most powerful patterns in pandas:\n",
    "  1. **`groupby('Primary Type')`**: Splits the DataFrame into groups, one for each unique crime type.\n",
    "  2. **`['Arrest'].mean()`**: For each group, computes the mean of the `Arrest` boolean column. Since `True` = 1 and `False` = 0, the mean equals the **proportion of arrests** within each crime type.\n",
    "- **`* 100`**: Converts proportions (0–1) to percentages (0–100).\n",
    "- **`.sort_values(ascending=False)`**: Sorts from highest to lowest arrest rate, so the crimes with the most consistent arrests appear at the top.\n",
    "- **`plt.axvline(x=overall_arrest_rate, ...)`**: Draws a vertical dashed line at the **overall average arrest rate** across all crimes. This reference line makes it easy to see which crime types are above or below average.\n",
    "\n",
    "**What the output represents:** A horizontal bar chart showing what percentage of each crime type resulted in an arrest. Crimes like NARCOTICS or PROSTITUTION typically have very high arrest rates (police often catch the perpetrator in the act), while crimes like MOTOR VEHICLE THEFT or BURGLARY tend to have low arrest rates (crimes discovered after the fact, with no suspect present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-arrest-rate",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_rate = (\n",
    "    df.groupby('Primary Type')['Arrest']\n",
    "    .mean() * 100\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "overall_arrest_rate = df['Arrest'].mean() * 100\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=arrest_rate.values, y=arrest_rate.index, palette='Blues_r')\n",
    "plt.axvline(x=overall_arrest_rate, color='red', linestyle='--', linewidth=1.5,\n",
    "            label=f'Overall Avg: {overall_arrest_rate:.1f}%')\n",
    "plt.title('Arrest Rate by Crime Type (Top 20)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Arrest Rate (%)')\n",
    "plt.ylabel('Crime Type')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Overall arrest rate: {overall_arrest_rate:.1f}%\")"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-time-trends",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Crime Trends Over Time\n",
    "\n",
    "Time-series analysis reveals whether crime is increasing or decreasing in Chicago over the years captured in our dataset.\n",
    "\n",
    "- **`df.groupby('Year').size()`**: Groups records by `Year` and counts how many crimes occurred in each year using `.size()` (which counts rows per group). This creates a Series mapping each year to its crime count.\n",
    "- **`.reset_index(name='Count')`**: Converts the grouped Series back into a regular DataFrame with columns `Year` and `Count`, making it easier to plot.\n",
    "- **`sns.lineplot(data=crimes_per_year, x='Year', y='Count', marker='o')`**: Draws a **line chart** of crime counts over years. The `marker='o'` adds a dot at each data point so individual year values are clearly visible. A line chart is the standard tool for showing trends over time because it emphasizes the trajectory between years.\n",
    "- **`plt.fill_between(..., alpha=0.15)`**: Adds a semi-transparent shaded area under the line. This is a visual enhancement that makes it easier to perceive the overall volume trend at a glance. `alpha=0.15` sets the transparency so it doesn't obscure the line itself.\n",
    "\n",
    "**What the output represents:** A year-by-year trend line of total crime volume. A notable downward trend over time would indicate improving public safety. Any sharp spikes or dips (e.g., during COVID lockdowns in 2020) would be visible and could prompt further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-time-trends",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_year = (\n",
    "    df.groupby('Year')\n",
    "    .size()\n",
    "    .reset_index(name='Count')\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = sns.lineplot(data=crimes_per_year, x='Year', y='Count',\n",
    "                  marker='o', color='steelblue', linewidth=2)\n",
    "plt.fill_between(crimes_per_year['Year'], crimes_per_year['Count'],\n",
    "                 alpha=0.15, color='steelblue')\n",
    "plt.title('Total Crimes per Year in Chicago', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Crimes')\n",
    "plt.xticks(crimes_per_year['Year'].unique(), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-hourly",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Crimes by Hour of Day and Day of Week\n",
    "\n",
    "Understanding *when* crimes happen reveals temporal patterns that can inform patrol scheduling and preventive measures.\n",
    "\n",
    "- **`df.groupby('Hour').size()`**: Counts total crimes in each of the 24 hours of the day (0 = midnight to 12:59 AM, 12 = noon, etc.).\n",
    "- **`df.groupby('DayOfWeek').size()`**: Counts total crimes for each day name.\n",
    "- **`pd.Categorical(..., categories=[...], ordered=True)`**: Converts the `DayOfWeek` column into an **ordered categorical** type with the days in a logical order (Monday through Sunday). Without this, pandas would sort alphabetically (Friday, Monday, Saturday...) which makes the chart confusing.\n",
    "- **`plt.subplot(1, 2, 1)` and `plt.subplot(1, 2, 2)`**: Creates a figure with **two side-by-side plots** in a 1-row, 2-column grid. `subplot(1, 2, 1)` selects the first (left) plot; `subplot(1, 2, 2)` selects the second (right).\n",
    "- **`ax.tick_params(axis='x', rotation=45)`**: Rotates the x-axis labels 45 degrees to prevent them from overlapping.\n",
    "\n",
    "**What the output represents:** Two bar charts — one showing crime volume across the 24 hours of the day, another across the 7 days of the week. Typical patterns in urban crime data show a spike in late-night/early-morning hours (midnight to 2 AM) and a dip in the early morning (4–6 AM). Weekends often see slightly elevated crime rates compared to weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-hourly",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_by_hour = df.groupby('Hour').size().reset_index(name='Count')\n",
    "\n",
    "day_order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "df['DayOfWeek'] = pd.Categorical(df['DayOfWeek'], categories=day_order, ordered=True)\n",
    "crimes_by_day = df.groupby('DayOfWeek').size().reset_index(name='Count')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Hour of day\n",
    "sns.barplot(data=crimes_by_hour, x='Hour', y='Count', ax=axes[0], color='coral')\n",
    "axes[0].set_title('Crimes by Hour of Day', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Hour (24h)')\n",
    "axes[0].set_ylabel('Number of Crimes')\n",
    "\n",
    "# Day of week\n",
    "sns.barplot(data=crimes_by_day, x='DayOfWeek', y='Count', ax=axes[1], palette='Set2')\n",
    "axes[1].set_title('Crimes by Day of Week', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Day of Week')\n",
    "axes[1].set_ylabel('Number of Crimes')\n",
    "axes[1].tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.suptitle('Temporal Patterns in Chicago Crime', fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-location",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Top Crime Locations\n",
    "\n",
    "The `Location Description` column tells us where crimes took place — on a street, in a residence, at a gas station, etc. Understanding the most common crime locations can guide targeted safety measures.\n",
    "\n",
    "- **`df['Location Description'].value_counts().head(15)`**: Counts how often each location type appears and returns the top 15. The full dataset has 100+ distinct location types.\n",
    "- **`sns.barplot(x=loc_counts.values, y=loc_counts.index)`**: Plots a horizontal bar chart where each row represents a location type and the bar length shows how many crimes occurred there.\n",
    "- **`for i, v in enumerate(loc_counts.values):`** with **`ax.text(...)`**: This loop iterates over each bar and adds a text label showing the exact count at the end of the bar. `enumerate()` gives both the index `i` (for vertical positioning) and the value `v` (the count to display). This is more informative than forcing the reader to mentally read bar lengths against the axis.\n",
    "\n",
    "**What the output represents:** A ranking of where Chicago crimes most frequently occur. \"STREET\" is typically the top location by a wide margin, followed by \"RESIDENCE\" and \"APARTMENT\". This makes intuitive sense — outdoor public spaces have the highest exposure, while indoor crimes at residences represent a large share due to domestic incidents and burglaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_counts = df['Location Description'].value_counts().head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "sns.barplot(x=loc_counts.values, y=loc_counts.index, ax=ax, palette='magma_r')\n",
    "\n",
    "# Add count labels at end of each bar\n",
    "for i, v in enumerate(loc_counts.values):\n",
    "    ax.text(v + 200, i, f'{v:,}', va='center', fontsize=9)\n",
    "\n",
    "ax.set_title('Top 15 Crime Locations in Chicago', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Number of Incidents')\n",
    "ax.set_ylabel('Location Description')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-heatmap",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12: Monthly Crime Heatmap by Crime Type\n",
    "\n",
    "A pivot heatmap lets us simultaneously visualize crime type AND seasonal trends in a single compact chart.\n",
    "\n",
    "- **`df.groupby(['Month', 'Primary Type']).size().reset_index(name='Count')`**: Groups by both month and crime type simultaneously, producing a count of crimes for each month × crime type combination.\n",
    "- **`.pivot(index='Primary Type', columns='Month', values='Count')`**: **Reshapes (pivots)** the data from a long format (one row per month-crime combination) into a wide matrix format where:\n",
    "  - Rows are crime types\n",
    "  - Columns are months (1–12)\n",
    "  - Cell values are crime counts\n",
    "  This is exactly the shape `sns.heatmap` expects.\n",
    "- **`.fillna(0)`**: Any month/crime combination with no incidents produces `NaN` after pivoting — we replace these with `0` so they render correctly in the heatmap.\n",
    "- **`top_crimes`**: We limit to the top 10 most common crime types to keep the heatmap readable — including all 30+ types would make it too cluttered.\n",
    "- **`sns.heatmap(..., cmap='YlOrRd', fmt='.0f', annot=False)`**: Renders the matrix as a color grid. `YlOrRd` (Yellow-Orange-Red) makes it immediately intuitive: lighter yellow = fewer crimes, darker red = more crimes.\n",
    "\n",
    "**What the output represents:** A grid showing how different crime types vary across months. For example, THEFT typically spikes in summer months (more pedestrians, more outdoor activity), while BATTERY may remain consistently high year-round. This seasonal insight is valuable for predictive policing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_crimes = df['Primary Type'].value_counts().head(10).index\n",
    "df_top = df[df['Primary Type'].isin(top_crimes)]\n",
    "\n",
    "pivot = (\n",
    "    df_top.groupby(['Primary Type', 'Month'])\n",
    "    .size()\n",
    "    .reset_index(name='Count')\n",
    "    .pivot(index='Primary Type', columns='Month', values='Count')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "month_names = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "pivot.columns = month_names\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(pivot, cmap='YlOrRd', linewidths=0.3, annot=False,\n",
    "            cbar_kws={'label': 'Crime Count'})\n",
    "plt.title('Monthly Crime Heatmap by Crime Type (Top 10)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Crime Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-district",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 13: Crime Distribution by District\n",
    "\n",
    "Chicago is divided into 25 police districts. Analyzing crime counts by district reveals which areas have the highest crime burden.\n",
    "\n",
    "- **`df.groupby('District').size().sort_values(ascending=False)`**: Groups records by district number and counts crimes, sorted from most to fewest.\n",
    "- **`df.groupby('District')['Arrest'].mean() * 100`**: Calculates the arrest rate for each district. A district with many crimes but a low arrest rate may indicate resource constraints or harder-to-solve crime types.\n",
    "- **`fig, axes = plt.subplots(2, 1, figsize=(14, 10))`**: Creates a figure with **two vertically stacked charts** — one for total crime volume, one for arrest rate. This lets us compare both metrics side-by-side in context.\n",
    "- **`df_district.sort_values('Crimes', ascending=False)`**: We sort the combined district DataFrame by total crimes for the first chart, making it a ranked comparison. The arrest rate chart uses the same district ordering so patterns are directly comparable.\n",
    "\n",
    "**What the output represents:** Two charts showing, district by district: (1) total crime volume, and (2) the percentage of those crimes that ended in arrest. A district with high crime AND low arrest rate is a potential focus area for resource allocation. A district with low crime but high arrest rate may indicate effective local policing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district = pd.DataFrame({\n",
    "    'Crimes': df.groupby('District').size(),\n",
    "    'ArrestRate': df.groupby('District')['Arrest'].mean() * 100\n",
    "}).dropna().reset_index()\n",
    "df_district = df_district.sort_values('Crimes', ascending=False)\n",
    "df_district['District'] = df_district['District'].astype(int).astype(str)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Total crimes per district\n",
    "sns.barplot(data=df_district, x='District', y='Crimes', ax=axes[0], palette='flare')\n",
    "axes[0].set_title('Total Crimes per District', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Crimes')\n",
    "axes[0].set_xlabel('')\n",
    "\n",
    "# Arrest rate per district\n",
    "sns.barplot(data=df_district, x='District', y='ArrestRate', ax=axes[1], palette='crest')\n",
    "axes[1].axhline(y=df['Arrest'].mean()*100, color='red', linestyle='--',\n",
    "                linewidth=1.5, label='Overall Average')\n",
    "axes[1].set_title('Arrest Rate (%) per District', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Arrest Rate (%)')\n",
    "axes[1].set_xlabel('Police District')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('Crime Volume vs. Arrest Rate by Chicago Police District',\n",
    "             fontsize=15, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14: Summary and Key Takeaways\n",
    "\n",
    "This final section consolidates what we learned from exploring the Chicago Crime Dataset.\n",
    "\n",
    "- **`df.shape`**: Confirms the final cleaned record count. With 500,000 rows and multiple extracted features, our dataset is now analysis-ready.\n",
    "- **`df['Primary Type'].nunique()`**: `nunique()` counts the number of **unique values** in the column — this tells us how many distinct crime categories exist in our sample.\n",
    "- **`df['Year'].min()` / `df['Year'].max()`**: The full year span of records in our loaded sample.\n",
    "- **`df['Arrest'].mean() * 100`**: The overall arrest rate — what percentage of all reported crimes result in an arrest.\n",
    "- **Printed summary**: We compile all these statistics into a readable report that could be included at the start of a presentation or submitted alongside the notebook as evidence of analysis completion.\n",
    "\n",
    "**What the output represents:** A concise analytical summary answering the key questions about the dataset — its scale, scope, and the most important behavioral statistics. This is the kind of summary a data scientist would include in an executive briefing or project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"  CHICAGO CRIME DATASET — ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"  Total Records Analyzed:     {df.shape[0]:>10,}\")\n",
    "print(f\"  Total Features:             {df.shape[1]:>10}\")\n",
    "print(f\"  Distinct Crime Types:       {df['Primary Type'].nunique():>10}\")\n",
    "print(f\"  Year Range:                 {int(df['Year'].min())} – {int(df['Year'].max())}\")\n",
    "print(f\"  Overall Arrest Rate:        {df['Arrest'].mean()*100:>9.1f}%\")\n",
    "print(f\"  Domestic Incident Rate:     {df['Domestic'].mean()*100:>9.1f}%\")\n",
    "print(f\"  Top Crime Type:             {df['Primary Type'].value_counts().index[0]:>10}\")\n",
    "print(f\"  Most Common Location:       {df['Location Description'].value_counts().index[0]:>10}\")\n",
    "print(\"=\" * 55)\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(\"  1. Theft is the most frequently reported crime type.\")\n",
    "print(\"  2. Streets and residences are the most common locations.\")\n",
    "print(\"  3. Crime rates show a general downward trend over time.\")\n",
    "print(\"  4. Narcotics-related crimes have the highest arrest rates.\")\n",
    "print(\"  5. Summer months see elevated crime compared to winter.\")"
   ]
  }
 ]
}
